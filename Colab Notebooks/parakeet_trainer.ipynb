{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21674,"status":"ok","timestamp":1744825327273,"user":{"displayName":"Walter Liu","userId":"11350568488805106686"},"user_tz":-60},"id":"sMjxeJEonmBC","outputId":"a9477d1c-0578-4e70-de2c-c3df6b518d69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: chess in /usr/local/lib/python3.11/dist-packages (1.11.2)\n","Requirement already satisfied: pytorch_optimizer in /usr/local/lib/python3.11/dist-packages (3.5.0)\n","Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_optimizer) (2.0.2)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from pytorch_optimizer) (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (4.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->pytorch_optimizer) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->pytorch_optimizer) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->pytorch_optimizer) (3.0.2)\n","Mounted at /content/drive\n","Running on the GPU\n"]}],"source":["import json, io\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","!pip install chess\n","!pip install pytorch_optimizer\n","import chess\n","import re\n","import random\n","import pickle\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# configuring device\n","try:\n","    device = xm.xla_device()\n","    print(\"Running on the TPU\")\n","except:\n","    if torch.cuda.is_available():\n","        device = torch.device('cuda:0')\n","        print('Running on the GPU')\n","        torch.cuda.synchronize()\n","    else:\n","        device = torch.device('cpu')\n","        print('Running on the CPU')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAm7qK3bnnwj"},"outputs":[],"source":["LONG_INTERVAL = 200\n","SHORT_INTERVAL = 10\n","\n","EVAL_SET_SIZE = 65536\n","PUZZLE_SET_SIZE = 4096\n","\n","# Stages:\n","EASY_PUZZLES = 0 # 75% easy puzzles, 9.375% mates, 3.125% openings, 6.25% midgames, 6.25% endgames\n","MID_PUZZLES = 1 # 12.5% easy puzzles, 62.5% mid puzzles, 6.25% mates, 3.125% openings, 9.375% midgames, 6.25% endgames\n","MID_CONSOLIDATION = 2 # 25% easy puzzles, 25% mid puzzles, 6.25% mates, 15.625% openings, 15.625% midgames, 12.5% endgames\n","HARD_PUZZLES = 3 # 6.25% easy puzzles, 9.375% mid puzzles, 50% hard puzzles, 12.5% mates, 6.25% openings, 9.375% midgames, 6.25% endgames\n","POSITIONAL = 4 # 3.125% easy puzzles, 6.25% mid puzzles, 9.375% hard puzzles, 6.25% mates, 25% openings, 25% midgames, 25% endgames\n","\n","# Types:\n","DRAW = 5\n","ADV = 6\n","WIN = 7\n","\n","# Total (rough, assuming equal training time):\n","# Easy puzzles: 22.4%, Mid puzzles: 19.3%, Hard puzzles: 12.0%, Mates: 7.8%, Openings: 10.9%, Midgames: 14.1%, Endgames: 13.5%\n","\n","STAGE = POSITIONAL\n","if STAGE in (EASY_PUZZLES, MID_PUZZLES, HARD_PUZZLES):\n","    EPOCH_SIZE = 65536\n","    BATCH_SIZE = 4096\n","    VAL_SIZE = 131072\n","elif STAGE in (MID_CONSOLIDATION, POSITIONAL):\n","    EPOCH_SIZE = 65536\n","    BATCH_SIZE = 2048\n","    VAL_SIZE = 131072\n","\n","learning_rate = 0.001\n","l2r = 0\n","checkpoint = 0\n","save = True\n","model_name = \"complex2_parrot\"\n","\n","TIME_CHECK = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LS0DisWEnp1N"},"outputs":[],"source":["class UltraSimpleModel(nn.Module):\n","\n","    def __init__(self, name):\n","        super().__init__()\n","\n","        self.name = name\n","\n","        self.conv_net = nn.Sequential()\n","        self.conv_net.add_module(\"Conv 1\", nn.Conv2d(1, 64, 8, 1))\n","        self.conv_net.add_module(\"Conv batchnorm 1\", nn.BatchNorm2d(64, momentum=0.2))\n","        self.conv_net.add_module(\"Conv activation 1\", nn.LeakyReLU())\n","        self.conv_net.add_module(\"Flattener\", nn.Flatten())\n","\n","        self.mlp = nn.Sequential()\n","        self.mlp.add_module(\"Layer 1\", nn.Linear(76, 1))\n","        self.mlp.add_module(\"Activation 1\", nn.Sigmoid())\n","\n","    def forward(self, x, feat):\n","        x = self.conv_net.forward(x)\n","        y = torch.column_stack((x, feat))\n","        return self.mlp.forward(y)\n","\n","    def count_parameters(self): return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","class SimpleModel(nn.Module):\n","\n","    def __init__(self, name):\n","        super().__init__()\n","\n","        self.name = name\n","\n","        self.conv_net = nn.Sequential()\n","        self.conv_net.add_module(\"Conv 1\", nn.Conv2d(1, 100, 2, 1))\n","        self.conv_net.add_module(\"Batchnorm 1\", nn.BatchNorm2d(100))\n","        self.conv_net.add_module(\"Conv activation\", nn.LeakyReLU())\n","        self.conv_net.add_module(\"Conv 2\", nn.Conv2d(100, 250, 2, 1))\n","        self.conv_net.add_module(\"Batchnorm 2\", nn.BatchNorm2d(250))\n","        self.conv_net.add_module(\"Conv activation 2\", nn.LeakyReLU())\n","        self.conv_net.add_module(\"Conv 3\", nn.Conv2d(250, 400, 3, 1))\n","        self.conv_net.add_module(\"Batchnorm 3\", nn.BatchNorm2d(400))\n","        self.conv_net.add_module(\"Conv activation 3\", nn.LeakyReLU())\n","        self.conv_net.add_module(\"Conv 4\", nn.Conv2d(400, 700, 4, 1))\n","        self.conv_net.add_module(\"Batchnorm 4\", nn.BatchNorm2d(700))\n","        self.conv_net.add_module(\"Conv activation 4\", nn.LeakyReLU())\n","        self.conv_net.add_module(\"Flattener\", nn.Flatten())\n","\n","        self.mlp = nn.Sequential()\n","        self.mlp.add_module(\"Layer 1\", nn.Linear(700, 500))\n","        self.mlp.add_module(\"Batchnorm 1\", nn.BatchNorm1d(500))\n","        self.mlp.add_module(\"Activation 1\", nn.LeakyReLU())\n","        self.mlp.add_module(\"Layer 2\", nn.Linear(500, 250))\n","        self.mlp.add_module(\"Activation 2\", nn.LeakyReLU())\n","        self.mlp.add_module(\"Layer 3\", nn.Linear(250, 1))\n","        self.mlp.add_module(\"Activation 3\", nn.Sigmoid())\n","\n","    def forward(self, x):\n","        x = self.conv_net.forward(x)\n","        return self.mlp.forward(x)\n","\n","    def count_parameters(self): return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","\n","class SE_Block(nn.Module):\n","    \"credits: https://github.com/moskomule/senet.pytorch/blob/master/senet/se_module.py#L4\"\n","    def __init__(self, c, r=16):\n","        super().__init__()\n","        self.squeeze = nn.AdaptiveAvgPool2d(1)\n","        self.excitation = nn.Sequential(\n","            nn.Linear(c, c // r, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(c // r, c, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        bs, c, _, _ = x.shape\n","        y = self.squeeze(x).view(bs, c)\n","        y = self.excitation(y).view(bs, c, 1, 1)\n","        return x * y.expand_as(x)\n","\n","class ComplexModel(nn.Module):\n","  # Attempt at using a deeper CNN.\n","\n","    def __init__(self, name):\n","        super().__init__()\n","\n","        self.name = name\n","\n","        self.conv_net = nn.Sequential()\n","        self.conv_net.add_module(\"Conv 1\", nn.Conv2d(1, 200, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 1\", SE_Block(200))\n","        self.conv_net.add_module(\"Batchnorm 1\", nn.BatchNorm2d(200))\n","        self.conv_net.add_module(\"Conv activation\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 2\", nn.Conv2d(200, 190, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 2\", SE_Block(190))\n","        self.conv_net.add_module(\"Batchnorm 2\", nn.BatchNorm2d(190))\n","        self.conv_net.add_module(\"Conv activation 2\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 3\", nn.Conv2d(190, 180, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 3\", SE_Block(180))\n","        self.conv_net.add_module(\"Batchnorm 3\", nn.BatchNorm2d(180))\n","        self.conv_net.add_module(\"Conv activation 3\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 4\", nn.Conv2d(180, 170, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 4\", SE_Block(170))\n","        self.conv_net.add_module(\"Batchnorm 4\", nn.BatchNorm2d(170))\n","        self.conv_net.add_module(\"Conv activation 4\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 5\", nn.Conv2d(170, 160, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 5\", SE_Block(160))\n","        self.conv_net.add_module(\"Batchnorm 5\", nn.BatchNorm2d(160))\n","        self.conv_net.add_module(\"Conv activation 5\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 6\", nn.Conv2d(160, 150, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 6\", SE_Block(150))\n","        self.conv_net.add_module(\"Batchnorm 6\", nn.BatchNorm2d(150))\n","        self.conv_net.add_module(\"Conv activation 6\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 7\", nn.Conv2d(150, 140, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 7\", SE_Block(140))\n","        self.conv_net.add_module(\"Batchnorm 7\", nn.BatchNorm2d(140))\n","        self.conv_net.add_module(\"Conv activation 7\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 8\", nn.Conv2d(140, 130, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 8\", SE_Block(130))\n","        self.conv_net.add_module(\"Batchnorm 8\", nn.BatchNorm2d(130))\n","        self.conv_net.add_module(\"Conv activation 8\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 9\", nn.Conv2d(130, 120, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 9\", SE_Block(120))\n","        self.conv_net.add_module(\"Batchnorm 9\", nn.BatchNorm2d(120))\n","        self.conv_net.add_module(\"Conv activation 9\", nn.Mish())\n","        self.conv_net.add_module(\"Conv 10\", nn.Conv2d(120, 110, 3, 1, 1))\n","        self.conv_net.add_module(\"SE 10\", SE_Block(110))\n","        self.conv_net.add_module(\"Batchnorm 10\", nn.BatchNorm2d(110))\n","        self.conv_net.add_module(\"Conv activation 10\", nn.Mish())\n","        self.conv_net.add_module(\"Flattener\", nn.Flatten())\n","\n","        self.mlp = nn.Sequential()\n","        self.mlp.add_module(\"Linear 1\", nn.Linear(7040, 1))\n","        self.mlp.add_module(\"Activation 1\", nn.Sigmoid())\n","\n","    def forward(self, x):\n","        a=self.conv_net(x)\n","        return self.mlp(self.conv_net(x))\n","\n","    def count_parameters(self): return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","\n","class MeanModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, a, b):\n","        return torch.mean(a)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1336,"status":"ok","timestamp":1744825328663,"user":{"displayName":"Walter Liu","userId":"11350568488805106686"},"user_tz":-60},"id":"muGgaIFzaWl_","outputId":"1072aba4-3a80-49dd-d804-b1fee5f53614"},"outputs":[{"output_type":"stream","name":"stdout","text":["5961751\n","2041051\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[0.5021],\n","        [0.4646]], device='cuda:0', grad_fn=<SigmoidBackward0>)"]},"metadata":{},"execution_count":4}],"source":["m = SimpleModel(\"test\")\n","print(m.count_parameters())\n","\n","m = ComplexModel(\"test\").to(device)\n","print(m.count_parameters())\n","m(torch.rand(2, 1, 8, 8, device=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34183,"status":"ok","timestamp":1744825362849,"user":{"displayName":"Walter Liu","userId":"11350568488805106686"},"user_tz":-60},"id":"CBnL5qBYnwFp","outputId":"57adaf03-e004-44ab-ea80-19cd98c80ce9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset info:\n","- Drawish positions: 65536 * 150 = 9,830,400\n","- Advantageous positions: 65536 * 250 = 16,384,000\n","- Winning positions: 65536 * 112 = 7,340,032\n","- Total = 33,554,432\n","\n","- Easy puzzles: 4096 * 213 =   872,448\n","- Mid puzzles : 4096 * 384 = 1,572,864\n","- Hard puzzles: 4096 * 152 =   622,592\n","- Total = 3,067,904\n","----------------\n","Target validation set size: 131072\n","Easy puzzle board validation set dimensions:  (4096, 1, 8, 8)\n","Mid puzzle board validation set dimensions:  (8192, 1, 8, 8)\n","Hard puzzle board validation set dimensions:  (8192, 1, 8, 8)\n","Draws board validation set dimensions:  (65536, 1, 8, 8)\n","Advantages board validation set dimensions:  (32768, 1, 8, 8)\n","Winning board validation set dimensions:  (12288, 1, 8, 8)\n","Total board validation set dimensions:  (131072, 1, 8, 8)\n"]}],"source":["# Curriculum learning\n","\n","def read_eval_data(phase, num):\n","    data_list = pickle.load(open(f\"/content/drive/MyDrive/parrot/evaluation_database/{phase}_data_{num}.chess\", \"rb\"))\n","    return data_list\n","\n","def read_puzzle_data(person, difficulty, num):\n","    data_list = pickle.load(open(f\"/content/drive/MyDrive/parrot/puzzle_database/data_{person}_{difficulty}_{num}.chess\", \"rb\"))\n","    return data_list\n","\n","print(\"Dataset info:\")\n","print(\"- Drawish positions: 65536 * 150 = 9,830,400\")\n","print(\"- Advantageous positions: 65536 * 250 = 16,384,000\")\n","print(\"- Winning positions: 65536 * 112 = 7,340,032\")\n","print(\"- Total = 33,554,432\")\n","print()\n","print(\"- Easy puzzles: 4096 * 213 =   872,448\")\n","print(\"- Mid puzzles : 4096 * 384 = 1,572,864\")\n","print(\"- Hard puzzles: 4096 * 152 =   622,592\")\n","print(\"- Total = 3,067,904\")\n","\n","print(\"----------------\")\n","\n","\n","# Filenames + 1 since indexing starts from 0.\n","EASY_DISTRIBUTION = [51, 37, 42, 41, 42]\n","MID_DISTRIBUTION = [92, 66, 76, 74, 76]\n","HARD_DISTRIBUTION = [36, 27, 30, 29, 30]\n","\n","EASY_PUZZLE_VALIDATION_SET = [[0, 5, 13, 21, 29, 37, 45, 50], [1, 6, 11, 16, 21, 26], [2, 8, 14, 20, 26, 32], [2, 8, 14, 20, 26, 32], [2, 8, 14, 20, 26, 32]]\n","MID_PUZZLE_VALIDATION_SET = [[1, 11, 21, 31, 41, 51, 61, 71], [2, 14, 26, 38, 50, 62], [3, 16, 29, 42, 55, 68], [4, 16, 28, 40, 52, 64], [5, 16, 27, 38, 49, 60]]\n","HARD_PUZZLE_VALIDATION_SET = [[3, 12, 20, 34], [1, 12, 26], [5, 10, 20], [5, 19, 24], [8, 18, 28]]\n","DRAW_VALIDATION_SET = [25, 125]\n","ADV_VALIDATION_SET = [75, 200]\n","WIN_VALIDATION_SET = [50, 100]\n","\n","# Build validation sets\n","print(\"Target validation set size:\", VAL_SIZE)\n","val_mid_puzzle_boards, val_mid_puzzle_evals, val_hard_puzzle_boards, val_hard_puzzle_evals = [], [], [], []\n","\n","# 3.125% easy puzzles, 6.25% mid puzzles, 6.25% hard puzzles, 34.375% draws, 25% advantages, 25% wins\n","if STAGE == POSITIONAL:\n","    num_easy_puzzles_sets = round((VAL_SIZE * 0.03125) / PUZZLE_SET_SIZE)\n","    val_easy_puzzle_boards = []\n","    val_easy_puzzle_evals = []\n","    for i in range(1):\n","        j = random.randint(0, len(EASY_PUZZLE_VALIDATION_SET[i]) - 1)\n","        vb, ve = read_puzzle_data(i, \"easy\", EASY_PUZZLE_VALIDATION_SET[i][j])\n","        val_easy_puzzle_boards += vb\n","        val_easy_puzzle_evals += ve\n","    print(\"Easy puzzle board validation set dimensions: \", np.shape(val_easy_puzzle_boards))\n","\n","    num_mid_puzzles_sets = round((VAL_SIZE * 0.0625) / PUZZLE_SET_SIZE)\n","    val_mid_puzzle_boards = []\n","    val_mid_puzzle_evals = []\n","    for i in range(1):\n","        j = random.randint(0, len(EASY_PUZZLE_VALIDATION_SET[i]) - 1)\n","        k = random.randint(0, len(EASY_PUZZLE_VALIDATION_SET[i]) - 1)\n","        while (j == k):\n","            j = random.randint(0, len(EASY_PUZZLE_VALIDATION_SET[i]) - 1)\n","\n","        vb, ve = read_puzzle_data(i, \"mid\", MID_PUZZLE_VALIDATION_SET[i][j])\n","        vb1, ve1 = read_puzzle_data(i, \"mid\", MID_PUZZLE_VALIDATION_SET[i][k])\n","        val_mid_puzzle_boards += (vb + vb1)\n","        val_mid_puzzle_evals += (ve + ve1)\n","    print(\"Mid puzzle board validation set dimensions: \", np.shape(val_mid_puzzle_boards))\n","\n","    num_hard_puzzles_sets = round((VAL_SIZE * 0.0625) / PUZZLE_SET_SIZE)\n","    val_hard_puzzle_boards = []\n","    val_hard_puzzle_evals = []\n","    for i in range(1, 3):\n","        for j in range(1):\n","            vb, ve = read_puzzle_data(i, \"hard\", HARD_PUZZLE_VALIDATION_SET[i][j])\n","            val_hard_puzzle_boards += vb\n","            val_hard_puzzle_evals += ve\n","    print(\"Hard puzzle board validation set dimensions: \", np.shape(val_hard_puzzle_boards))\n","\n","    num_draws = round(VAL_SIZE * 0.5)\n","    val_draw_boards, val_draw_evals = read_eval_data(\"draw\", DRAW_VALIDATION_SET[0])\n","    vb, ve = read_eval_data(\"draw\", DRAW_VALIDATION_SET[1])\n","    val_draw_boards += vb[:(num_draws - EVAL_SET_SIZE)]\n","    val_draw_evals += ve[:(num_draws - EVAL_SET_SIZE)]\n","    print(\"Draws board validation set dimensions: \", np.shape(val_draw_boards))\n","\n","    num_advs = round(VAL_SIZE * 0.25)\n","    val_adv_boards, val_adv_evals = [], []\n","    vb, ve = read_eval_data(\"adv\", ADV_VALIDATION_SET[0])\n","    val_adv_boards += vb[:num_advs]\n","    val_adv_evals += ve[:num_advs]\n","    print(\"Advantages board validation set dimensions: \", np.shape(val_adv_boards))\n","\n","    num_wins = int(VAL_SIZE * 0.09375)\n","    vb, ve = read_eval_data(\"winning\", WIN_VALIDATION_SET[0])\n","    val_win_boards, val_win_feats, val_win_evals = [], [], []\n","    val_win_boards += vb[:num_wins]\n","    val_win_evals += ve[:num_wins]\n","    print(\"Winning board validation set dimensions: \", np.shape(val_win_boards))\n","\n","val_position_list = list(val_easy_puzzle_boards) + list(val_mid_puzzle_boards) + list(val_hard_puzzle_boards) + list(val_draw_boards) + list(val_adv_boards) + list(val_win_boards)\n","val_eval_list = list(val_easy_puzzle_evals) + list(val_mid_puzzle_evals) + list(val_hard_puzzle_evals) + list(val_draw_evals) + list(val_adv_evals) + list(val_win_evals)\n","\n","print(\"Total board validation set dimensions: \", np.shape(val_position_list))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H8prwMKPCfQ7"},"outputs":[],"source":["# Training data loader\n","\n","class DataLoader:\n","\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","        self.pointer = 0\n","        if self.dataset in [EASY_PUZZLES, MID_PUZZLES, HARD_PUZZLES]:\n","            self.length = 4096\n","        elif self.dataset in [DRAW, ADV, WIN]:\n","            self.length = 65536\n","        self.data = None\n","\n","    def get_dataset(self):\n","        if self.dataset in [EASY_PUZZLES, MID_PUZZLES, HARD_PUZZLES]:\n","            rp = random.randint(0, 4)\n","            if self.dataset == EASY_PUZZLES:\n","                ri = random.randint(0, EASY_DISTRIBUTION[rp] - 1)\n","                while ri in EASY_PUZZLE_VALIDATION_SET[rp]:\n","                    ri = random.randint(0, EASY_DISTRIBUTION[rp] - 1)\n","                self.data = read_puzzle_data(rp, \"easy\", ri)\n","            elif self.dataset == MID_PUZZLES:\n","                ri = random.randint(0, MID_DISTRIBUTION[rp] - 1)\n","                while ri in MID_PUZZLE_VALIDATION_SET[rp]:\n","                    ri = random.randint(0, MID_DISTRIBUTION[rp] - 1)\n","                self.data = read_puzzle_data(rp, \"mid\", ri)\n","            elif self.dataset == HARD_PUZZLES:\n","                ri = random.randint(0, HARD_DISTRIBUTION[rp] - 1)\n","                while ri in HARD_PUZZLE_VALIDATION_SET[rp]:\n","                    ri = random.randint(0, HARD_DISTRIBUTION[rp] - 1)\n","                self.data = read_puzzle_data(rp, \"hard\", ri)\n","\n","        elif self.dataset in [DRAW, ADV, WIN]:\n","            if self.dataset == DRAW:\n","                ri = random.randint(0, 149)\n","                while ri in DRAW_VALIDATION_SET:\n","                    ri = random.randint(0, 149)\n","                self.data = read_eval_data(\"draw\", ri)\n","            elif self.dataset == ADV:\n","                ri = random.randint(0, 249)\n","                while ri in ADV_VALIDATION_SET:\n","                    ri = random.randint(0, 249)\n","                self.data = read_eval_data(\"adv\", ri)\n","            elif self.dataset == WIN:\n","                ri = random.randint(0, 111)\n","                while ri in WIN_VALIDATION_SET:\n","                    ri = random.randint(0, 111)\n","                self.data = read_eval_data(\"winning\", ri)\n","\n","    def get_data(self, num):\n","        res_pos, res_eval = [], []\n","        if self.data is None:\n","            self.get_dataset()\n","        while num > 0:\n","            res_pos += self.data[0][self.pointer : num + self.pointer]\n","            res_eval += self.data[1][self.pointer : num + self.pointer]\n","            if num >= self.length - self.pointer:\n","                num -= (self.length - self.pointer)\n","                self.pointer = 0\n","                self.get_dataset()\n","            else:\n","                self.pointer += num\n","                num = 0\n","        return res_pos, res_eval\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"M3HFBUWrnyH5","outputId":"eabf83b2-9900-4b98-ec64-9ef7418f3430","executionInfo":{"status":"error","timestamp":1744828317323,"user_tz":-60,"elapsed":2954409,"user":{"displayName":"Walter Liu","userId":"11350568488805106686"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading from last checkpoint.\n","Best validation loss at checkpoint: 0.013924401515396312\n","ComplexModel(\n","  (conv_net): Sequential(\n","    (Conv 1): Conv2d(1, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 1): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=200, out_features=12, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=12, out_features=200, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 1): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation): Mish()\n","    (Conv 2): Conv2d(200, 190, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 2): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=190, out_features=11, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=11, out_features=190, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 2): BatchNorm2d(190, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 2): Mish()\n","    (Conv 3): Conv2d(190, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 3): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=180, out_features=11, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=11, out_features=180, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 3): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 3): Mish()\n","    (Conv 4): Conv2d(180, 170, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 4): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=170, out_features=10, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=10, out_features=170, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 4): BatchNorm2d(170, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 4): Mish()\n","    (Conv 5): Conv2d(170, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 5): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=160, out_features=10, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=10, out_features=160, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 5): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 5): Mish()\n","    (Conv 6): Conv2d(160, 150, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 6): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=150, out_features=9, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=9, out_features=150, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 6): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 6): Mish()\n","    (Conv 7): Conv2d(150, 140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 7): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=140, out_features=8, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=8, out_features=140, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 7): BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 7): Mish()\n","    (Conv 8): Conv2d(140, 130, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 8): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=130, out_features=8, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=8, out_features=130, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 8): BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 8): Mish()\n","    (Conv 9): Conv2d(130, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 9): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=120, out_features=7, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=7, out_features=120, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 9): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 9): Mish()\n","    (Conv 10): Conv2d(120, 110, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (SE 10): SE_Block(\n","      (squeeze): AdaptiveAvgPool2d(output_size=1)\n","      (excitation): Sequential(\n","        (0): Linear(in_features=110, out_features=6, bias=False)\n","        (1): ReLU(inplace=True)\n","        (2): Linear(in_features=6, out_features=110, bias=False)\n","        (3): Sigmoid()\n","      )\n","    )\n","    (Batchnorm 10): BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (Conv activation 10): Mish()\n","    (Flattener): Flatten(start_dim=1, end_dim=-1)\n","  )\n","  (mlp): Sequential(\n","    (Linear 1): Linear(in_features=7040, out_features=1, bias=True)\n","    (Activation 1): Sigmoid()\n","  )\n",")\n","Batch size =  2048\n","Validation size =  131072\n","L2 regularisation strength = 0\n","Learning rate = 3e-05\n","Stage:  4\n","Data loaded in 7.610460996627808 seconds. Mean 7.610460996627808, Stdev 0.0\n","[-------------------- ]     Loss 0.011706\n","Epoch 1461, loss 0.01122, completed in 28.519895792007446 seconds.\n","Validation loss 0.014037 completed in 19.56547498703003 seconds.\n","Data loaded in 4.2481207847595215 seconds. Mean 5.9292908906936646, Stdev 1.681170105934143\n","[-------------------- ]     Loss 0.011839\n","Epoch 1462, loss 0.012274, completed in 26.797325611114502 seconds.\n","Validation loss 0.014041 completed in 21.34906315803528 seconds.\n","Data loaded in 2.684779167175293 seconds. Mean 4.847786982854207, Stdev 2.0551212507785954\n","[-------------------- ]     Loss 0.011271\n","Epoch 1463, loss 0.011964, completed in 28.66623044013977 seconds.\n","Validation loss 0.014036 completed in 21.20799970626831 seconds.\n","Data loaded in 4.951846361160278 seconds. Mean 4.873801827430725, Stdev 1.7803575014491768\n","[-------------------- ]     Loss 0.010718\n","Epoch 1464, loss 0.011537, completed in 27.72663140296936 seconds.\n","Validation loss 0.014042 completed in 21.834514141082764 seconds.\n","Data loaded in 1.1482553482055664 seconds. Mean 4.128692531585694, Stdev 2.1809378068601135\n","[-------------------- ]     Loss 0.012433\n","Epoch 1465, loss 0.012963, completed in 28.67251467704773 seconds.\n","Validation loss 0.014006 completed in 21.44874358177185 seconds.\n","Data loaded in 3.5735840797424316 seconds. Mean 4.036174456278483, Stdev 2.0016341829746485\n","[-------------------- ]     Loss 0.012523\n","Epoch 1466, loss 0.013019, completed in 27.909400463104248 seconds.\n","Validation loss 0.013985 completed in 21.66698718070984 seconds.\n","Data loaded in 1.1428697109222412 seconds. Mean 3.6228452069418773, Stdev 2.1116872497641834\n","[-------------------- ]     Loss 0.010691\n","Epoch 1467, loss 0.011413, completed in 27.833854913711548 seconds.\n","Validation loss 0.013971 completed in 21.311766386032104 seconds.\n","Data loaded in 8.61077094078064 seconds. Mean 4.246335923671722, Stdev 2.5735199392374284\n","[-------------------- ]     Loss 0.011171\n","Epoch 1468, loss 0.011556, completed in 28.117835521697998 seconds.\n","Validation loss 0.013975 completed in 21.88539457321167 seconds.\n","Data loaded in 2.4353952407836914 seconds. Mean 4.045120292239719, Stdev 2.4921912626166884\n","[-------------------- ]     Loss 0.011911\n","Epoch 1469, loss 0.012071, completed in 27.730072736740112 seconds.\n","Validation loss 0.013983 completed in 21.478021383285522 seconds.\n","Data loaded in 4.57478404045105 seconds. Mean 4.098086667060852, Stdev 2.3696338308422047\n","[-------------------- ]     Loss 0.011023\n","Epoch 1470, loss 0.012289, completed in 28.98635506629944 seconds.\n","Validation loss 0.013986 completed in 21.680699825286865 seconds.\n","Data loaded in 3.791494369506836 seconds. Mean 4.070214640010487, Stdev 2.2610757377614354\n","[-------------------- ]     Loss 0.012947\n","Epoch 1471, loss 0.01227, completed in 28.305089712142944 seconds.\n","Validation loss 0.013979 completed in 21.670396089553833 seconds.\n","Data loaded in 4.083393096923828 seconds. Mean 4.071312844753265, Stdev 2.164818268159985\n","[-------------------- ]     Loss 0.011408\n","Epoch 1472, loss 0.012095, completed in 27.761738061904907 seconds.\n","Validation loss 0.013985 completed in 21.508378267288208 seconds.\n","Data loaded in 2.548579692840576 seconds. Mean 3.954179525375366, Stdev 2.1191001550591815\n","[-------------------- ]     Loss 0.011561\n","Epoch 1473, loss 0.012532, completed in 27.996651887893677 seconds.\n","Validation loss 0.01396 completed in 21.461852550506592 seconds.\n","Data loaded in 2.2637312412261963 seconds. Mean 3.833433219364711, Stdev 2.0879092599468256\n","[-------------------- ]     Loss 0.011523\n","Epoch 1474, loss 0.012615, completed in 27.989784717559814 seconds.\n","Validation loss 0.013954 completed in 21.443814754486084 seconds.\n","Data loaded in 2.199254274368286 seconds. Mean 3.7244879563649493, Stdev 2.0578891427564336\n","[-------------------- ]     Loss 0.011353\n","Epoch 1475, loss 0.012258, completed in 28.844329595565796 seconds.\n","Validation loss 0.013944 completed in 21.6399507522583 seconds.\n","Data loaded in 8.27612829208374 seconds. Mean 4.008965477347374, Stdev 2.276870196189765\n","[-------------------- ]     Loss 0.011987\n","Epoch 1476, loss 0.011557, completed in 27.86726999282837 seconds.\n","Validation loss 0.013954 completed in 21.919254541397095 seconds.\n","Data loaded in 0.9996306896209717 seconds. Mean 3.8319457839517033, Stdev 2.3196043094094803\n","[-------------------- ]     Loss 0.010929\n","Epoch 1477, loss 0.01131, completed in 27.8032283782959 seconds.\n","Validation loss 0.013943 completed in 21.217752933502197 seconds.\n","Data loaded in 7.50719952583313 seconds. Mean 4.036126547389561, Stdev 2.406318817662916\n","[-------------------- ]     Loss 0.0108\n","Epoch 1478, loss 0.011537, completed in 28.13603973388672 seconds.\n","Validation loss 0.01395 completed in 21.752187490463257 seconds.\n","Data loaded in 1.1408922672271729 seconds. Mean 3.8837457958020667, Stdev 2.4297267347074474\n","[-------------------- ]     Loss 0.010151\n","Epoch 1479, loss 0.011015, completed in 27.715251684188843 seconds.\n","Validation loss 0.013975 completed in 21.311416149139404 seconds.\n","Data loaded in 8.165098428726196 seconds. Mean 4.097813427448273, Stdev 2.545401239989132\n","[-------------------- ]     Loss 0.012169\n","Epoch 1480, loss 0.01199, completed in 29.01815128326416 seconds.\n","Validation loss 0.013987 completed in 21.968531370162964 seconds.\n","Data loaded in 3.028862237930298 seconds. Mean 4.0469109898521785, Stdev 2.494466198027321\n","[-------------------- ]     Loss 0.010718\n","Epoch 1481, loss 0.012074, completed in 28.13963556289673 seconds.\n","Validation loss 0.013982 completed in 21.692260265350342 seconds.\n","Data loaded in 6.405853748321533 seconds. Mean 4.154135660691694, Stdev 2.486155008259352\n","[-------------------- ]     Loss 0.012642\n","Epoch 1482, loss 0.012013, completed in 28.127174615859985 seconds.\n","Validation loss 0.013953 completed in 21.56994128227234 seconds.\n","Data loaded in 0.9157767295837402 seconds. Mean 4.013337446295696, Stdev 2.519595217349325\n","[-------------------- ]     Loss 0.011125\n","Epoch 1483, loss 0.012245, completed in 27.84864830970764 seconds.\n","Validation loss 0.013955 completed in 21.284456253051758 seconds.\n","Data loaded in 5.569895029067993 seconds. Mean 4.078194012244542, Stdev 2.486079576802151\n","[-------------------- ]     Loss 0.010164\n","Epoch 1484, loss 0.011075, completed in 27.93969225883484 seconds.\n","Validation loss 0.013951 completed in 21.74310302734375 seconds.\n","Data loaded in 4.507965087890625 seconds. Mean 4.095384855270385, Stdev 2.4373060123258203\n","[-------------------- ]     Loss 0.012362\n","Epoch 1485, loss 0.01274, completed in 28.612178802490234 seconds.\n","Validation loss 0.01396 completed in 21.737081050872803 seconds.\n","Data loaded in 3.289644718170166 seconds. Mean 4.0643948499973, Stdev 2.3949928715200373\n","[-------------------- ]     Loss 0.012242\n","Epoch 1486, loss 0.011888, completed in 27.893013954162598 seconds.\n","Validation loss 0.013927 completed in 21.473984241485596 seconds.\n","Data loaded in 2.132413387298584 seconds. Mean 3.992839981008459, Stdev 2.378375355170196\n","[-------------------- ]     Loss 0.012642\n","Epoch 1487, loss 0.012596, completed in 27.984789848327637 seconds.\n","Validation loss 0.013928 completed in 21.392075777053833 seconds.\n","Data loaded in 5.576709508895874 seconds. Mean 4.049406749861581, Stdev 2.3539413772594755\n","[-------------------- ]     Loss 0.012744\n","Epoch 1488, loss 0.012231, completed in 27.995932579040527 seconds.\n","Validation loss 0.013937 completed in 21.578505277633667 seconds.\n","Data loaded in 1.0204827785491943 seconds. Mean 3.944961095678395, Stdev 2.378112426581757\n","[-------------------- ]     Loss 0.012053\n","Epoch 1489, loss 0.012356, completed in 27.898731470108032 seconds.\n","Validation loss 0.013926 completed in 21.277354955673218 seconds.\n","Data loaded in 3.8621089458465576 seconds. Mean 3.9421993573506673, Stdev 2.338188603407836\n","[-------------------- ]     Loss 0.011934\n","Epoch 1490, loss 0.012084, completed in 28.83837890625 seconds.\n","Validation loss 0.01392 completed in 21.784066438674927 seconds.\n","New best model!\n","Data loaded in 2.67364239692688 seconds. Mean 3.9012781650789323, Stdev 2.3110610902698903\n","[-------------------- ]     Loss 0.011215\n","Epoch 1491, loss 0.012009, completed in 28.104881525039673 seconds.\n","Validation loss 0.013936 completed in 21.911906480789185 seconds.\n","Data loaded in 5.543124437332153 seconds. Mean 3.9525858610868454, Stdev 2.2925321977293636\n","[-------------------- ]     Loss 0.010782\n","Epoch 1492, loss 0.01198, completed in 27.892690181732178 seconds.\n","Validation loss 0.013934 completed in 21.517821073532104 seconds.\n","Data loaded in 2.0707826614379883 seconds. Mean 3.895561521703547, Stdev 2.2804598073164164\n","[-------------------- ]     Loss 0.01106\n","Epoch 1493, loss 0.011704, completed in 27.992171049118042 seconds.\n","Validation loss 0.013926 completed in 21.325767040252686 seconds.\n","Data loaded in 4.4651031494140625 seconds. Mean 3.9123127460479736, Stdev 2.2487332115453595\n","[-------------------- ]     Loss 0.011601\n","Epoch 1494, loss 0.011657, completed in 27.98805594444275 seconds.\n","Validation loss 0.013932 completed in 21.6270592212677 seconds.\n","Data loaded in 1.2740564346313477 seconds. Mean 3.836933994293213, Stdev 2.259537018475925\n","[-------------------- ]     Loss 0.011173\n","Epoch 1495, loss 0.011941, completed in 28.74029278755188 seconds.\n","Validation loss 0.01394 completed in 21.53032112121582 seconds.\n","Data loaded in 5.379167079925537 seconds. Mean 3.879773802227444, Stdev 2.242302745854807\n","[-------------------- ]     Loss 0.011685\n","Epoch 1496, loss 0.011077, completed in 27.97555112838745 seconds.\n","Validation loss 0.013973 completed in 21.624724864959717 seconds.\n","Data loaded in 0.8682410717010498 seconds. Mean 3.798381025726731, Stdev 2.2650660161193783\n","[-------------------- ]     Loss 0.011565\n","Epoch 1497, loss 0.011675, completed in 27.746474742889404 seconds.\n","Validation loss 0.013947 completed in 21.359029531478882 seconds.\n","Data loaded in 3.423480272293091 seconds. Mean 3.7885152164258455, Stdev 2.2358693234494336\n","[-------------------- ]     Loss 0.01039\n","Epoch 1498, loss 0.011129, completed in 27.985390186309814 seconds.\n","Validation loss 0.013934 completed in 21.530334949493408 seconds.\n","Data loaded in 3.736762523651123 seconds. Mean 3.7871882243034167, Stdev 2.207033347397143\n","[-------------------- ]     Loss 0.011305\n","Epoch 1499, loss 0.011033, completed in 27.81248903274536 seconds.\n","Validation loss 0.013958 completed in 21.557860136032104 seconds.\n","Data loaded in 4.330842733383179 seconds. Mean 3.800779587030411, Stdev 2.1809231009139807\n","[-------------------- ]     Loss 0.012001\n","Epoch 1500, loss 0.011865, completed in 28.820414066314697 seconds.\n","Validation loss 0.013947 completed in 21.679704189300537 seconds.\n","Data loaded in 1.1207568645477295 seconds. Mean 3.7354131791649796, Stdev 2.193473474510719\n","[-------------------- ]     Loss 0.01142\n","Epoch 1501, loss 0.011555, completed in 28.677300691604614 seconds.\n","Validation loss 0.013943 completed in 21.660120010375977 seconds.\n","Data loaded in 2.8692986965179443 seconds. Mean 3.7147914057686218, Stdev 2.171222251236571\n","[-------------------- ]     Loss 0.013352\n","Epoch 1502, loss 0.012886, completed in 27.929659128189087 seconds.\n","Validation loss 0.01393 completed in 21.309645175933838 seconds.\n","Data loaded in 2.1322388648986816 seconds. Mean 3.67798785830653, Stdev 2.159042012453491\n","[-------------------- ]     Loss 0.010131\n","Epoch 1503, loss 0.011168, completed in 28.066218376159668 seconds.\n","Validation loss 0.013927 completed in 21.472511053085327 seconds.\n","Data loaded in 5.814870357513428 seconds. Mean 3.7265533696521413, Stdev 2.157994501005841\n","[-------------------- ]     Loss 0.011465\n","Epoch 1504, loss 0.011715, completed in 28.09713578224182 seconds.\n","Validation loss 0.01394 completed in 21.629018306732178 seconds.\n","Data loaded in 2.8272998332977295 seconds. Mean 3.7065699577331546, Stdev 2.137995210935043\n","[-------------------- ]     Loss 0.010572\n","Epoch 1505, loss 0.011623, completed in 28.677518606185913 seconds.\n","Validation loss 0.013943 completed in 21.626876831054688 seconds.\n","Data loaded in 1.9604542255401611 seconds. Mean 3.668610920076785, Stdev 2.1299045588258796\n","[-------------------- ]     Loss 0.011483\n","Epoch 1506, loss 0.011281, completed in 27.957059860229492 seconds.\n","Validation loss 0.013947 completed in 21.496732711791992 seconds.\n","Data loaded in 3.8214151859283447 seconds. Mean 3.6718620746693715, Stdev 2.107239548126764\n","[-------------------- ]     Loss 0.012266\n","Epoch 1507, loss 0.012117, completed in 27.89771842956543 seconds.\n","Validation loss 0.013945 completed in 21.477405786514282 seconds.\n","Data loaded in 5.360067367553711 seconds. Mean 3.7070330182711286, Stdev 2.099068302533712\n","[-------------------- ]     Loss 0.013215\n","Epoch 1508, loss 0.012956, completed in 27.84785532951355 seconds.\n","Validation loss 0.013939 completed in 21.73241877555847 seconds.\n","Data loaded in 2.228954315185547 seconds. Mean 3.676868146779586, Stdev 2.0880238780794462\n","[-------------------- ]     Loss 0.011495\n","Epoch 1509, loss 0.012181, completed in 27.970394372940063 seconds.\n","Validation loss 0.013916 completed in 21.349457025527954 seconds.\n","New best model!\n","Data loaded in 2.894636631011963 seconds. Mean 3.6612235164642337, Stdev 2.0699371511108327\n","[-------------------- ]     Loss 0.012218\n","Epoch 1510, loss 0.011821, completed in 28.90439772605896 seconds.\n","Validation loss 0.013907 completed in 21.657109022140503 seconds.\n","New best model!\n","Data loaded in 0.13199353218078613 seconds. Mean 3.5920229285371073, Stdev 2.107145778710281\n","[-------------------- ]     Loss 0.013022\n","Epoch 1511, loss 0.012523, completed in 28.487425565719604 seconds.\n","Validation loss 0.013935 completed in 21.876775979995728 seconds.\n","Data loaded in 4.630373477935791 seconds. Mean 3.6119912083332357, Stdev 2.0916531360418107\n","[-------------------- ]     Loss 0.011918\n","Epoch 1512, loss 0.012304, completed in 27.776780366897583 seconds.\n","Validation loss 0.013918 completed in 21.531569004058838 seconds.\n","Data loaded in 2.4177310466766357 seconds. Mean 3.5894579977359413, Stdev 2.0781886823770974\n","[-------------------- ]     Loss 0.011661\n","Epoch 1513, loss 0.011902, completed in 27.961723804473877 seconds.\n","Validation loss 0.01393 completed in 21.45601534843445 seconds.\n","Data loaded in 5.2274205684661865 seconds. Mean 3.6197906379346496, Stdev 2.070664825384144\n","[-------------------- ]     Loss 0.011546\n","Epoch 1514, loss 0.012095, completed in 28.110709190368652 seconds.\n","Validation loss 0.013925 completed in 21.617485523223877 seconds.\n","Data loaded in 3.5095632076263428 seconds. Mean 3.617786502838135, Stdev 2.0518071033125924\n","[-------------------- ]     Loss 0.011681\n","Epoch 1515, loss 0.012742, completed in 28.718726873397827 seconds.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ed4773427650>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0mtvl\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvl\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVAL_SIZE\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import time\n","import random\n","import os\n","import math\n","import statistics\n","\n","model = ComplexModel(model_name).to(device=device)\n","\n","checkpoint = -1\n","learning_rate = 0.00003\n","l2r = 0\n","\n","from pytorch_optimizer import SOAP\n","optimizer = SOAP(model.parameters(), lr=learning_rate)\n","loss_fn = nn.MSELoss()\n","\n","\n","if checkpoint == 0:\n","    num_epoch = 0\n","    best_vloss = 1000\n","    model.train()\n","    with open(f\"/content/drive/MyDrive/parrot/{model_name}_loss.csv\", \"w\") as file:\n","        file.write(\"\")\n","    print(\"Using new models.\")\n","\n","elif checkpoint == -1:\n","    print(\"Loading from last checkpoint.\")\n","    checkpoint_file = torch.load(f\"/content/drive/MyDrive/parrot/{model_name}.pickle\", weights_only=True, map_location=device)\n","    model.load_state_dict(checkpoint_file[\"model_state_dict\"])\n","    model.to(device=device)\n","    #optimizer.load_state_dict(checkpoint_file[\"optimizer_state_dict\"])\n","\n","    # Update learning rate in case it is changed midway.\n","    for g in optimizer.param_groups:\n","      g['lr'] = learning_rate\n","\n","    num_epoch = checkpoint_file[\"epoch\"] + 1\n","    best_vloss = checkpoint_file[\"best_loss\"]\n","    model.train()\n","    print(f\"Best validation loss at checkpoint: {best_vloss}\")\n","\n","elif checkpoint == -2:\n","    print(\"Switching to new dataset.\")\n","    checkpoint_file = torch.load(f\"/content/drive/MyDrive/parrot/{model_name}.pickle\", weights_only=True, map_location=device)\n","    model.load_state_dict(checkpoint_file[\"model_state_dict\"])\n","    model.to(device=device)\n","\n","    # Update learning rate in case it is changed midway.\n","    for g in optimizer.param_groups:\n","      g['lr'] = learning_rate\n","\n","    num_epoch = 0\n","    best_vloss = 1000\n","    model.train()\n","\n","\n","else:\n","    print(f\"Loading from epoch {checkpoint}.\")\n","    checkpoint_file = torch.load(f\"/content/drive/MyDrive/parrot/{model_name}_{checkpoint}.pickle\", weights_only=True, map_location=device)\n","    model.load_state_dict(checkpoint_file[\"model_state_dict\"])\n","    model.to(device=device)\n","    optimizer.load_state_dict(checkpoint_file[\"optimizer_state_dict\"])\n","\n","    # Update learning rate in case it is changed midway.\n","    for g in optimizer.param_groups:\n","      g['lr'] = learning_rate\n","\n","    num_epoch = checkpoint_file[\"epoch\"] + 1\n","    best_vloss = checkpoint_file[\"best_loss\"]\n","    model.train()\n","    print(f\"Best validation loss at checkpoint: {best_vloss}\")\n","\n","\n","\n","print(model)\n","print(\"Batch size = \", BATCH_SIZE)\n","print(\"Validation size = \", VAL_SIZE)\n","print(\"L2 regularisation strength =\", l2r)\n","print(\"Learning rate =\", learning_rate)\n","print(\"Stage: \", STAGE)\n","\n","def warmup_then_expo(epoch):\n","  if epoch < 58:\n","    return epoch / 58\n","  else:\n","    return (0.999 ** (epoch - 58))\n","#scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_then_expo)\n","\n","tlr, tl, vl = [], [], []\n","\n","running_mean = 0\n","M2 = 0\n","readings = 0\n","\n","# Setup dataloaders\n","easy_puzzle_loader = DataLoader(EASY_PUZZLES)\n","mid_puzzle_loader = DataLoader(MID_PUZZLES)\n","hard_puzzle_loader = DataLoader(HARD_PUZZLES)\n","draw_loader = DataLoader(DRAW)\n","adv_loader = DataLoader(ADV)\n","win_loader = DataLoader(WIN)\n","\n","for epoch in range(num_epoch, 800000):\n","\n","    bl, el = [], []\n","    bl4, el4, bl5, el5, bl6, el6 = [], [], [], [], [], []\n","    start = time.time()\n","\n","    # 6.25% easy puzzles, 12.5% mid puzzles, 12.5% hard puzzles, 6.25% mates, 18.75% openings, 21.875% midgames, 21.875% endgames\n","    if STAGE == POSITIONAL:\n","        bl0, el0 = easy_puzzle_loader.get_data(round(EPOCH_SIZE * 0.03125))\n","        bl1, el1 = mid_puzzle_loader.get_data(round(EPOCH_SIZE * 0.0625))\n","        bl2, el2 = hard_puzzle_loader.get_data(round(EPOCH_SIZE * 0.0625))\n","        bl3, el3 = draw_loader.get_data(round(EPOCH_SIZE * 0.5))\n","        bl4, el4 = adv_loader.get_data(round(EPOCH_SIZE * 0.25))\n","        bl5, el5 = win_loader.get_data(round(EPOCH_SIZE * 0.09375))\n","\n","    bl = (bl0 + bl1 + bl2 + bl3 + bl4 + bl5 + bl6)\n","    el = (el0 + el1 + el2 + el3 + el4 + el5 + el6)\n","\n","    #print(\"Shape of training set boards:\", np.shape(bl))\n","\n","\n","    zipped = list(zip(bl, el))\n","    random.shuffle(zipped)\n","    bl, el = zip(*zipped)\n","\n","    cl = 0\n","    clr = 0\n","    norms = []\n","    data_load_time = time.time() - start\n","    readings += 1\n","    delta = data_load_time - running_mean\n","    running_mean += delta / readings\n","    delta2 = data_load_time - running_mean\n","    M2 += (delta * delta2)\n","    variance = M2 / readings\n","    print(f\"Data loaded in {data_load_time} seconds. Mean {running_mean}, Stdev {variance ** 0.5}\")\n","    if (len(bl) != EPOCH_SIZE) or (len(el) != EPOCH_SIZE):\n","        print(\"Dataset is invalid.\")\n","        continue\n","    else:\n","        start = time.time()\n","        for batch in range(EPOCH_SIZE // BATCH_SIZE):\n","            tb = torch.tensor(bl[batch * BATCH_SIZE : (batch + 1) * BATCH_SIZE], device=device, dtype=torch.float).reshape(BATCH_SIZE, 1, 8, 8)\n","            te = torch.tensor(el[batch * BATCH_SIZE : (batch + 1) * BATCH_SIZE], device=device, dtype=torch.float).reshape(BATCH_SIZE, 1)\n","\n","            optimizer.zero_grad()\n","            out = model.forward(tb)\n","            loss = loss_fn(out, te)\n","            l = loss.item()\n","            cl += l\n","            if l2r != 0:\n","                l2 = sum(p.pow(2).sum() for p in model.parameters())\n","                loss += l2 * l2r\n","                llr = loss.item()\n","                clr += llr\n","            loss.backward()\n","\n","            # Gradient monitoring and clipping\n","            #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.03)\n","\n","            total_norm = 0\n","            parameters = [p for p in model.parameters() if p.grad is not None and p.requires_grad]\n","            for p in parameters:\n","                param_norm = p.grad.detach().data.norm(2)\n","                total_norm += param_norm.item() ** 2\n","            total_norm = total_norm ** 0.5\n","            norms.append(total_norm)\n","\n","            optimizer.step()\n","            tl.append(l)\n","            if l2r != 0:\n","                tlr.append(llr)\n","            completion = int(20 * batch / (EPOCH_SIZE // BATCH_SIZE)) + 1\n","            if l2r != 0:\n","                print(\"\\r\" + f\"[{'-' * completion} {' ' * (20 - completion)}]     Loss {round(l, 6)}, Regularised loss {round(llr, 6)}\", end = \"\")\n","            else:\n","                print(\"\\r\" + f\"[{'-' * completion} {' ' * (20 - completion)}]     Loss {round(l, 6)}\", end = \"\")\n","        if l2r != 0: print(f\"\\nEpoch {epoch}, loss {round(cl / (EPOCH_SIZE // BATCH_SIZE), 6)}, regularised loss {round(clr / (EPOCH_SIZE // BATCH_SIZE), 6)}, completed in {time.time() - start} seconds.\")\n","        else: print(f\"\\nEpoch {epoch}, loss {round(cl / (EPOCH_SIZE // BATCH_SIZE), 6)}, completed in {time.time() - start} seconds.\")\n","\n","        with torch.no_grad():\n","            model.eval()\n","            tvl = 0\n","            start = time.time()\n","            for vbatch in range(VAL_SIZE // BATCH_SIZE):\n","                vp = torch.tensor(val_position_list[vbatch * BATCH_SIZE : (vbatch + 1) * BATCH_SIZE], device=device, dtype=torch.float).reshape(BATCH_SIZE, 1, 8, 8)\n","                ve = torch.tensor(val_eval_list[vbatch * BATCH_SIZE : (vbatch + 1) * BATCH_SIZE], device=device, dtype=torch.float).reshape(BATCH_SIZE, 1)\n","                out = model.forward(vp)\n","                loss = loss_fn(out, ve)\n","                tvl += loss.item()\n","\n","            print(\"Validation loss\", round(tvl / (VAL_SIZE // BATCH_SIZE), 6), \"completed in\", time.time() - start, \"seconds.\")\n","            vl.append(tvl / (VAL_SIZE // BATCH_SIZE))\n","            if (tvl / (VAL_SIZE // BATCH_SIZE)) < best_vloss:\n","                print(\"New best model!\")\n","                best_vloss = tvl / (VAL_SIZE // BATCH_SIZE)\n","                torch.save(model.state_dict(), f\"/content/drive/MyDrive/parrot/best_{model_name}.pickle\")\n","\n","            model.train()\n","\n","        #before_lr = learning_rate\n","        #learning_rate *= 2\n","        #for g in optimizer.param_groups:\n","        #    g['lr'] = learning_rate\n","        #print(f\"Epoch {epoch} : lr {before_lr} -> {learning_rate}\")\n","\n","\n","        if save:\n","            if epoch % LONG_INTERVAL == 0:\n","                torch.save({\"epoch\": epoch, \"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict(), \"best_loss\": best_vloss}, f\"/content/drive/MyDrive/parrot/{model_name}_{epoch}.pickle\")\n","            if epoch % SHORT_INTERVAL == 0:\n","                torch.save({\"epoch\": epoch, \"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict(), \"best_loss\": best_vloss}, f\"/content/drive/MyDrive/parrot/{model_name}.pickle\")\n","            try:\n","                os.remove(f\"/content/drive/MyDrive/parrot/{model_name}_{epoch - LONG_INTERVAL}.pickle\")\n","            except:\n","                pass\n","\n","        with open(f\"/content/drive/MyDrive/parrot/{model_name}_loss.csv\", \"a\") as file:\n","            file.write(f\"{epoch}, {round(cl / (EPOCH_SIZE // BATCH_SIZE), 6)}, {round(tvl / (VAL_SIZE // BATCH_SIZE), 6)}, {round(max(norms), 6)}\\n\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1730487925438}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}